{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WOMEN WHO CODE - DATA ANALYTICS WITH PYTHON (INTERMEDIATE)\n",
    "\n",
    "## Introduction to Natural Language Processing\n",
    "## Categorizing, Tagging and Classifying\n",
    "\n",
    "Based on Natural Language Processing with Python (Authors: Steven Bird, Ewan Klein & Edward Loper)\n",
    "Published by O'Reilly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nltk.download()\n",
    "\n",
    "Download the NLTK Book Collection (30 compressed files about 100Mb disk space) to complete the exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### COLLOCATIONS AND N-GRAMS\n",
    "\n",
    "A collocation is a sequence of words that occur together unsually often. Thus *red wine* is a collocation.\n",
    "A characteristic of collocations is that they are resistant to substitution with words that have similar senses; for example *maroon wine* sounds very odd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.util import bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.collocations import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "United States; fellow citizens; four years; years ago; Federal\n",
      "Government; General Government; American people; Vice President; Old\n",
      "World; Almighty God; Fellow citizens; Chief Magistrate; Chief Justice;\n",
      "God bless; every citizen; Indian tribes; public debt; one another;\n",
      "foreign nations; political parties\n"
     ]
    }
   ],
   "source": [
    "text4.collocations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bigram_measures = nltk.collocations.BigramAssocMeasures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trigram_measures = nltk.collocations.TrigramAssocMeasures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "finder = BigramCollocationFinder.from_words(nltk.corpus.genesis.words('english-web.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, the top ten bigram collocations in Genesis are listed below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Allon', 'Bacuth'),\n",
       " ('Ashteroth', 'Karnaim'),\n",
       " ('Ben', 'Ammi'),\n",
       " ('En', 'Mishpat'),\n",
       " ('Jegar', 'Sahadutha'),\n",
       " ('Salt', 'Sea'),\n",
       " ('Whoever', 'sheds'),\n",
       " ('appoint', 'overseers'),\n",
       " ('aromatic', 'resin'),\n",
       " ('cutting', 'instrument')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finder.nbest(bigram_measures.pmi, 10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import webtext\n",
    "from nltk.collocations import BigramCollocationFinder\n",
    "from nltk.metrics import BigramAssocMeasures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = [w.lower() for w in webtext.words('grail.txt')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bcf = BigramCollocationFinder.from_words(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"'\", 's'), ('arthur', ':'), ('#', '1'), (\"'\", 't')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bcf.nbest(BigramAssocMeasures.likelihood_ratio, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminating Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopset = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filter_stops = lambda w: len(w) < 3 or w in stopset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bcf.apply_word_filter(filter_stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('black', 'knight'),\n",
       " ('clop', 'clop'),\n",
       " ('head', 'knight'),\n",
       " ('mumble', 'mumble')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bcf.nbest(BigramAssocMeasures.likelihood_ratio, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TAGGING\n",
    "\n",
    "A part-of-speech tagger, or POS tagger, processes a sequence of words, and attaches\n",
    "a part of speech tag to each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = nltk.word_tokenize(\"And now for something completely different\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('And', 'CC'),\n",
       " ('now', 'RB'),\n",
       " ('for', 'IN'),\n",
       " ('something', 'NN'),\n",
       " ('completely', 'RB'),\n",
       " ('different', 'JJ')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLTK provides documentation for each tag, which can be queried using the tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RB: adverb\n",
      "    occasionally unabatingly maddeningly adventurously professedly\n",
      "    stirringly prominently technologically magisterially predominately\n",
      "    swiftly fiscally pitilessly ...\n"
     ]
    }
   ],
   "source": [
    "nltk.help.upenn_tagset('RB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how NLTK behaves when working with homonyms which are words that have the same spelling but different meanings and origins. NLTK will analyze the whole regular expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = nltk.word_tokenize(\"They refuse to permit us to obtain the refuse permit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('They', 'PRP'),\n",
       " ('refuse', 'VBP'),\n",
       " ('to', 'TO'),\n",
       " ('permit', 'VB'),\n",
       " ('us', 'PRP'),\n",
       " ('to', 'TO'),\n",
       " ('obtain', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('refuse', 'NN'),\n",
       " ('permit', 'NN')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise:\n",
    "\n",
    "Create an example of a regular expression using homonyms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TAGGING CORPORA\n",
    "\n",
    "A tagged token is represented using a tuple consisting of the token and the tag. Use the function str2tuple():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tagged_token = nltk.tag.str2tuple('fly/NN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fly', 'NN')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fly'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_token[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NN'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_token[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can create a complex tagged sentence..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sent = '''\n",
    "... The/AT grand/JJ jury/NN commented/VBD on/IN a/AT number/NN of/IN\n",
    "... other/AP topics/NNS ,/, AMONG/IN them/PPO the/AT Atlanta/NP and/CC\n",
    "... Fulton/NP-tl County/NN-tl purchasing/VBG departments/NNS which/WDT it/PPS\n",
    "... said/VBD ``/`` ARE/BER well/QL operated/VBN and/CC follow/VB generally/RB\n",
    "... accepted/VBN practices/NNS which/WDT inure/VB to/IN the/AT best/JJT\n",
    "... interest/NN of/IN both/ABX governments/NNS ''/'' ./.\n",
    "... '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'AT'),\n",
       " ('grand', 'JJ'),\n",
       " ('jury', 'NN'),\n",
       " ('commented', 'VBD'),\n",
       " ('on', 'IN'),\n",
       " ('a', 'AT'),\n",
       " ('number', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('other', 'AP'),\n",
       " ('topics', 'NNS'),\n",
       " (',', ','),\n",
       " ('AMONG', 'IN'),\n",
       " ('them', 'PPO'),\n",
       " ('the', 'AT'),\n",
       " ('Atlanta', 'NP'),\n",
       " ('and', 'CC'),\n",
       " ('Fulton', 'NP-TL'),\n",
       " ('County', 'NN-TL'),\n",
       " ('purchasing', 'VBG'),\n",
       " ('departments', 'NNS'),\n",
       " ('which', 'WDT'),\n",
       " ('it', 'PPS'),\n",
       " ('said', 'VBD'),\n",
       " ('``', '``'),\n",
       " ('ARE', 'BER'),\n",
       " ('well', 'QL'),\n",
       " ('operated', 'VBN'),\n",
       " ('and', 'CC'),\n",
       " ('follow', 'VB'),\n",
       " ('generally', 'RB'),\n",
       " ('accepted', 'VBN'),\n",
       " ('practices', 'NNS'),\n",
       " ('which', 'WDT'),\n",
       " ('inure', 'VB'),\n",
       " ('to', 'IN'),\n",
       " ('the', 'AT'),\n",
       " ('best', 'JJT'),\n",
       " ('interest', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('both', 'ABX'),\n",
       " ('governments', 'NNS'),\n",
       " (\"''\", \"''\"),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[nltk.tag.str2tuple(t) for t in sent.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'AT'), ('Fulton', 'NP-TL'), ...]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.brown.tagged_words()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several of the corpora included with NLTK have been tagged for their part-of-speech.Other corpora use a variety of formats for storing part-of-speech tags. NLTK's corpus readers provide a uniform interface so that you don't have to be concerned with the different file formats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### USING A UNIVERSAL TAGSET\n",
    "\n",
    "Tag   Meaning\t            Examples   \n",
    "ADJ\t  adjective:\t        new, good, high, special, big, local   \n",
    "ADV\t  adverb:\t            really, already, still, early, now   \n",
    "CNJ\t  conjunction:        and, or, but, if, while, although  \n",
    "DET\t  determiner:\t        the, a, some, most, every, no  \n",
    "EX\t  existential:\t        there, there's  \n",
    "FW\t  foreign word:        dolce, ersatz, esprit, quo, maitre  \n",
    "MOD\t  modal verb:\t        will, can, would, may, must, should  \n",
    "N\t  noun:\t            year, home, costs, time, education  \n",
    "NP\t  proper noun:\t        Alison, Africa, April, Washington  \n",
    "NUM\t  number:\t            twenty-four, fourth, 1991, 14:24  \n",
    "PRO\t  pronoun:\t            he, their, her, its, my, I, us       \n",
    "P\t  preposition:\t        on, of, at, with, by, into, under     \n",
    "TO\t  the word to:\t        to   \n",
    "UH\t  interjection:        ah, bang, ha, whee, hmpf, oops   \n",
    "V\t  verb:\t            is, has, get, do, make, see, run    \n",
    "VD\t  past tense:\t        said, took, told, made, asked    \n",
    "VG\t  present participle:\tmaking, going, playing, working   \n",
    "VN\t  past participle:\t    given, taken, begun, sung      \n",
    "WH\t  wh determiner:\t    who, which, when, what, where, how    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the latest version of simplified tag is to map them to the universal tagset (https://code.google.com/p/universal-pos-tags/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DET'),\n",
       " ('Fulton', 'NOUN'),\n",
       " ('County', 'NOUN'),\n",
       " ('Grand', 'ADJ'),\n",
       " ('Jury', 'NOUN'),\n",
       " ('said', 'VERB'),\n",
       " ('Friday', 'NOUN'),\n",
       " ('an', 'DET'),\n",
       " ('investigation', 'NOUN'),\n",
       " ('of', 'ADP')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown.tagged_words(tagset='universal')[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "brown_news_tagged = brown.tagged_words(categories = 'news', tagset='universal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tag_fd = nltk.FreqDist(tag for (word, tag) in brown_news_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['PRON', 'ADV', 'VERB', 'PRT', 'X', 'ADJ', 'CONJ', 'ADP', 'NUM', 'DET', 'NOUN', '.'])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_fd.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the above frequency distribution using tag_fd.plot(cumulative=True). What percentage of words are tagged using the first five tags of the above list?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tag_fd.plot(cumulative=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAINING A UNI-GRAM Tagging\n",
    "\n",
    "- Unigram taggers are based on a simple statistical algorithm: for each token, assign the tag that is most likely for that particular token. \n",
    "- For example, it will assign the tag JJ to any occurrence of the word frequent, since frequent is used as an adjective (e.g., a frequent word) more often than it is used as a verb (e.g., I frequent this cafe).\n",
    "- A unigram tagger behaves just like a lookup tagger\n",
    "- In the following code sample, we train a unigram tagger, use it to tag a sentence, and then evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "brown_tagged_sents = brown.tagged_sents(categories='news')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "brown_sents = brown.sents(categories='news')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unigram_tagger = nltk.UnigramTagger(brown_tagged_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Various', 'JJ'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'AT'),\n",
       " ('apartments', 'NNS'),\n",
       " ('are', 'BER'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'AT'),\n",
       " ('terrace', 'NN'),\n",
       " ('type', 'NN'),\n",
       " (',', ','),\n",
       " ('being', 'BEG'),\n",
       " ('on', 'IN'),\n",
       " ('the', 'AT'),\n",
       " ('ground', 'NN'),\n",
       " ('floor', 'NN'),\n",
       " ('so', 'QL'),\n",
       " ('that', 'CS'),\n",
       " ('entrance', 'NN'),\n",
       " ('is', 'BEZ'),\n",
       " ('direct', 'JJ'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_tagger.tag(brown_sents[2007])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9349006503968017"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_tagger.evaluate(brown_tagged_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train a UnigramTagger by specifying tagged sentence data as a parameter when we\n",
    "initialize the tagger. The training process involves inspecting the tag of each word and\n",
    "storing the most likely tag for any word in a dictionary that is stored inside the tagger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREATING A TRAINING AND A TESTING DATA SETS\n",
    "\n",
    "A tagger that simply memorized its training data and made no attempt to construct a general model would get a perfect\n",
    "score, but would be useless for tagging new text. Instead, we should split the data,\n",
    "training on 90% and testing on the remaining 10%:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "size = int(len(brown_tagged_sents) * 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4160"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_sents = brown_tagged_sents[:size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_sents = brown_tagged_sents[size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unigram_tagger = nltk.UnigramTagger(train_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8122196750722616"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " unigram_tagger.evaluate(test_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GENERAL N-GRAM TAGGING\n",
    "\n",
    "An n-gram tagger is a generalization of a unigram tagger whose context is the current\n",
    "word together with the part-of-speech tags of the n-1 preceding tokens.\n",
    "The **NgramTagger class** uses a tagged training corpus to determine which part-of-speech\n",
    "tag is most likely for each context. Here we see a special case of an n-gram tagger,\n",
    "namely a bigram tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bigram_tagger = nltk.BigramTagger(train_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Various', 'JJ'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'AT'),\n",
       " ('apartments', 'NNS'),\n",
       " ('are', 'BER'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'AT'),\n",
       " ('terrace', 'NN'),\n",
       " ('type', 'NN'),\n",
       " (',', ','),\n",
       " ('being', 'BEG'),\n",
       " ('on', 'IN'),\n",
       " ('the', 'AT'),\n",
       " ('ground', 'NN'),\n",
       " ('floor', 'NN'),\n",
       " ('so', 'CS'),\n",
       " ('that', 'CS'),\n",
       " ('entrance', 'NN'),\n",
       " ('is', 'BEZ'),\n",
       " ('direct', 'JJ'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_tagger.tag(brown_sents[2007])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unseen_sent = brown_sents[4203]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'AT'),\n",
       " ('population', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'AT'),\n",
       " ('Congo', 'NP'),\n",
       " ('is', 'BEZ'),\n",
       " ('13.5', None),\n",
       " ('million', None),\n",
       " (',', None),\n",
       " ('divided', None),\n",
       " ('into', None),\n",
       " ('at', None),\n",
       " ('least', None),\n",
       " ('seven', None),\n",
       " ('major', None),\n",
       " ('``', None),\n",
       " ('culture', None),\n",
       " ('clusters', None),\n",
       " (\"''\", None),\n",
       " ('and', None),\n",
       " ('innumerable', None),\n",
       " ('tribes', None),\n",
       " ('speaking', None),\n",
       " ('400', None),\n",
       " ('separate', None),\n",
       " ('dialects', None),\n",
       " ('.', None)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " bigram_tagger.tag(unseen_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the bigram tagger manages to tag every word in a sentence it saw during\n",
    "training, but does badly on an unseen sentence. As soon as it encounters a new word, it is unable to assign a tag. It cannot tag the following word, even if it was seen during training, simply because it never saw it during training with a None tag on the previous word. Consequently, the tagger fails to tag the rest of the\n",
    "sentence. Its overall accuracy score is very low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10335891557859066"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_tagger.evaluate(test_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion:\n",
    "\n",
    "As n gets larger, the specificity of the contexts increases, as does the chance that the\n",
    "data we wish to tag contains contexts that were not present in the training data. This\n",
    "is known as the sparse data problem, and is quite pervasive in NLP. As a consequence,\n",
    "there is a trade-off between the accuracy and the coverage of our results (and this is\n",
    "related to the precision/recall trade-off in information retrieval)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COMBINING TAGGERS\n",
    "\n",
    "One way to address the trade-off between accuracy and coverage is to use the more\n",
    "accurate algorithms when we can, but to fall back on algorithms with wider coverage\n",
    "when necessary. For example, we could combine the results of a bigram tagger, a\n",
    "unigram tagger, and a default tagger, as follows:\n",
    "1. Try tagging the token with the bigram tagger.\n",
    "2. If the bigram tagger is unable to find a tag for the token, try the unigram tagger.\n",
    "3. If the unigram tagger is also unable to find a tag, use a default tagger.\n",
    "Most NLTK taggers permit a backoff tagger to be specified. The backoff tagger may\n",
    "itself have a backoff tagger. These taggers inherit from SequentialBackoffTagger, which allows them to be chained together for greater accuracy. \n",
    "\n",
    "more info at: http://streamhacker.com/2008/11/03/part-of-speech-tagging-with-nltk-part-1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t0 = nltk.DefaultTagger('NN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t1 = nltk.UnigramTagger(train_sents, backoff=t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t2 = nltk.BigramTagger(train_sents, backoff=t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8461078441144224"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " t2.evaluate(test_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A useful method to tag unknown words based on context is to limit the vocabulary of\n",
    "a tagger to the most frequent n words, and to replace every other word with a special\n",
    "word UNK.\n",
    "During training, a unigram tagger will probably learn that UNK is usually a noun. However, the n-gram taggers will detect contexts in which it has some other tag. For example, if the preceding word is to (tagged TO), then UNK will probably be tagged as a verb."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STORE AND RETRIEVE A MODEL\n",
    "\n",
    "Training a tagger on a large corpus may take a significant time. Instead of training a\n",
    "tagger every time we need one, it is convenient to save a trained tagger in a file for later\n",
    "reuse. Let’s save our tagger t2 to a file t2.pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>> from cPickle import dump\n",
    ">>> output = open('t2.pkl', 'wb')\n",
    ">>> dump(t2, output, -1)\n",
    ">>> output.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, in a separate Python process, we can load our saved tagger:\n",
    ">>> from cPickle import load\n",
    ">>> input = open('t2.pkl', 'rb')\n",
    ">>> tagger = load(input)\n",
    ">>> input.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s check that it can be used for tagging:\n",
    ">>> text = \"\"\"The board's action shows what free enterprise\n",
    "... is up against in our complex maze of regulatory laws .\"\"\"\n",
    ">>> tokens = text.split()\n",
    ">>> tagger.tag(tokens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
